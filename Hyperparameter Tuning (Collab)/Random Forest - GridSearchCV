{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNdXmL0wM3AFwg54N8iQfG8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9OU1NXoAbVT6","executionInfo":{"status":"error","timestamp":1741468921308,"user_tz":360,"elapsed":2891909,"user":{"displayName":"Andrew Castillo","userId":"02822267340440655112"}},"outputId":"071f04fd-24a3-4f38-90ef-9dbf70df0bbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Applying medication-based feature engineering...\n","Applying SMOTENC for class balancing...\n","Encoding categorical features...\n","Class weights: {0: 1.0, 1: 7.679632569743706}\n","\n","Select parameter grid size:\n","1: Minimal (fastest, lowest memory usage)\n","2: Reduced (recommended for standard Colab)\n","3: Full (may require high-memory runtime)\n","Enter choice (1-3), default is 2: 2\n","Using recommended reduced parameter grid\n","\n","Available memory before grid search: 48.66 GB\n","Using class weights in the model\n","Starting grid search with the following parameters:\n","n_estimators: [100, 200]\n","max_depth: [10, 20, None]\n","min_samples_split: [5, 10]\n","min_samples_leaf: [2, 4]\n","class_weight: ['balanced', 'balanced_subsample', {0: 1.0, 1: 7.679632569743706}]\n","Running grid search (this may take some time)...\n","Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Grid search completed in 46.69 minutes!\n","\n","Best parameters: {'class_weight': 'balanced_subsample', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n","Best F2 score: 0.6023499140971051\n","Best model saved to 'best_rf_model.joblib'\n","\n","Training Performance Metrics:\n","Best parameters: {'class_weight': 'balanced_subsample', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n","Best cross-validation F2 score: 0.6023\n"]},{"output_type":"error","ename":"ValueError","evalue":"The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- diag_1_114\n- diag_1_250.51\n- diag_1_318\n- diag_1_325\n- diag_1_372\n- ...\nFeature names seen at fit time, yet now missing:\n- acetohexamide_Steady\n- chlorpropamide_Down\n- diag_1_10\n- diag_1_11\n- diag_1_131\n- ...\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cd6c26b022cf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;31m# Make predictions - get probability for positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# Try different threshold values to optimize F2 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m     \"\"\"\n\u001b[0;32m-> 2919\u001b[0;31m     \u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2775\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Feature names must be in the same order as they were in fit.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- diag_1_114\n- diag_1_250.51\n- diag_1_318\n- diag_1_325\n- diag_1_372\n- ...\nFeature names seen at fit time, yet now missing:\n- acetohexamide_Steady\n- chlorpropamide_Down\n- diag_1_10\n- diag_1_11\n- diag_1_131\n- ...\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import make_scorer, fbeta_score, classification_report, confusion_matrix\n","from imblearn.over_sampling import SMOTENC\n","import gc\n","import psutil\n","import time\n","from joblib import dump\n","\n","# âœ… Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Feature engineering function for medication features\n","def create_medication_features(df):\n","    \"\"\"\n","    Create medication-based features for hospital readmission prediction.\n","    \"\"\"\n","    # Create a copy to avoid modifying the original\n","    data = df.copy()\n","\n","    # List of all medication columns\n","    med_columns = [\n","        'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n","        'glimepiride', 'acetohexamide', 'glipizide', 'glyburide',\n","        'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n","        'miglitol', 'troglitazone', 'tolazamide', 'insulin',\n","        'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone',\n","        'metformin-pioglitazone'\n","    ]\n","\n","    # 1. Total Medication Count\n","    data['med_count'] = data[med_columns].apply(lambda x: (x != 'No').sum(), axis=1)\n","    data['on_multiple_meds'] = (data['med_count'] >= 3).astype(int)\n","\n","    # 2. Medication Changes\n","    data['med_changes_up'] = data[med_columns].apply(lambda x: (x == 'Up').sum(), axis=1)\n","    data['med_changes_down'] = data[med_columns].apply(lambda x: (x == 'Down').sum(), axis=1)\n","    data['med_changes_total'] = data['med_changes_up'] + data['med_changes_down']\n","    data['has_med_changes'] = (data['med_changes_total'] > 0).astype(int)\n","\n","    # 3. Insulin Dependency Features\n","    data['insulin_binary'] = (data['insulin'] != 'No').astype(int)\n","    data['insulin_increased'] = (data['insulin'] == 'Up').astype(int)\n","    data['insulin_decreased'] = (data['insulin'] == 'Down').astype(int)\n","    data['insulin_steady'] = (data['insulin'] == 'Steady').astype(int)\n","\n","    # 4. Medication Combinations\n","    data['insulin_plus_oral'] = ((data['insulin'] != 'No') &\n","                                (data[med_columns].apply(lambda x: sum(x != 'No') > 1, axis=1))).astype(int)\n","\n","    # Metformin combinations\n","    metformin_cols = [col for col in med_columns if 'metformin' in col]\n","    data['any_metformin'] = (data[metformin_cols].apply(lambda x: (x != 'No').any(), axis=1)).astype(int)\n","\n","    # Sulfonylureas\n","    sulfonylureas = ['glimepiride', 'glipizide', 'glyburide', 'chlorpropamide', 'tolbutamide']\n","    data['any_sulfonylurea'] = (data[sulfonylureas].apply(lambda x: (x != 'No').any(), axis=1)).astype(int)\n","\n","    # Thiazolidinediones (TZDs)\n","    tzds = ['pioglitazone', 'rosiglitazone', 'troglitazone']\n","    data['any_tzd'] = (data[tzds].apply(lambda x: (x != 'No').any(), axis=1)).astype(int)\n","\n","    # Combined therapy indicators\n","    data['metformin_plus_sulfonylurea'] = (data['any_metformin'] & data['any_sulfonylurea']).astype(int)\n","    data['insulin_plus_metformin'] = (data['insulin_binary'] & data['any_metformin']).astype(int)\n","\n","    # 5. Treatment Intensity Indicator\n","    data['treatment_intensity'] = (\n","        data['med_count'] +\n","        2 * data['insulin_binary'] +\n","        1.5 * data['med_changes_total']\n","    )\n","\n","    return data\n","\n","def encode_categorical_features(df, categorical_columns):\n","    \"\"\"\n","    Encode categorical features for Random Forest (one-hot encoding)\n","\n","    Parameters:\n","    df (pandas.DataFrame): DataFrame containing categorical columns\n","    categorical_columns (list): List of categorical column names\n","\n","    Returns:\n","    pandas.DataFrame: DataFrame with one-hot encoded categorical features\n","    \"\"\"\n","    df_encoded = df.copy()\n","\n","    # One-hot encode categorical columns\n","    for col in categorical_columns:\n","        # Convert to string to handle any potential non-string categorical values\n","        df_encoded[col] = df_encoded[col].astype(str)\n","\n","        # Get dummies (one-hot encoding)\n","        dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=False)\n","\n","        # Add dummy columns to dataframe\n","        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n","\n","        # Drop original column\n","        df_encoded.drop(col, axis=1, inplace=True)\n","\n","    return df_encoded\n","\n","# --- Main Execution ---\n","\n","df = pd.read_parquet(\"/content/drive/MyDrive/ML Project/cleaned_hospital_readmission.parquet\")\n","# 2. Prepare data\n","df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x == \"<30\" else 0)\n","\n","# Apply feature engineering\n","print(\"Applying medication-based feature engineering...\")\n","df_enriched = create_medication_features(df)\n","\n","# Split into features and target\n","X = df_enriched.drop(columns=[\"readmitted\"])  # Features\n","y = df_enriched[\"readmitted\"]  # Target variable\n","\n","# Identify categorical columns\n","cat_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# Calculate cat_indices for SMOTE\n","cat_indices = [X.columns.get_loc(col) for col in cat_columns]\n","\n","# Train-test split with stratification\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","# Apply SMOTENC\n","print(\"Applying SMOTENC for class balancing...\")\n","smote = SMOTENC(sampling_strategy=0.3, random_state=42, categorical_features=cat_indices)\n","X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n","\n","# Handle NaN values and prepare data for Random Forest\n","print(\"Encoding categorical features...\")\n","X_train_balanced_encoded = encode_categorical_features(X_train_balanced, cat_columns)\n","X_test_encoded = encode_categorical_features(X_test, cat_columns)\n","\n","# Custom scorer for F2\n","f2_scorer = make_scorer(fbeta_score, beta=2)\n","\n","# Calculate class weights for imbalanced data\n","class_counts = y_train.value_counts()\n","class_weight_dict = {0: 1.0, 1: class_counts[0] / class_counts[1]}\n","print(f\"Class weights: {class_weight_dict}\")\n","\n","# 8. Define parameter grids for Random Forest\n","# Minimal grid - fastest, least memory intensive\n","minimal_param_grid = {\n","    'n_estimators': [100],\n","    'max_depth': [10],\n","    'min_samples_split': [10],\n","    'min_samples_leaf': [4]\n","}\n","\n","# Reduced grid - moderate memory usage\n","reduced_param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [5, 10],\n","    'min_samples_leaf': [2, 4]\n","}\n","\n","# Full grid - may cause memory issues\n","full_param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['sqrt', 'log2', None]\n","}\n","\n","# Let user choose grid size based on available memory\n","print(\"\\nSelect parameter grid size:\")\n","print(\"1: Minimal (fastest, lowest memory usage)\")\n","print(\"2: Reduced (recommended for standard Colab)\")\n","print(\"3: Full (may require high-memory runtime)\")\n","\n","grid_choice = input(\"Enter choice (1-3), default is 2: \") or \"2\"\n","\n","if grid_choice == \"1\":\n","    chosen_param_grid = minimal_param_grid\n","    print(\"Using minimal parameter grid\")\n","elif grid_choice == \"3\":\n","    chosen_param_grid = full_param_grid\n","    print(\"Using full parameter grid - warning: this may crash due to memory limits\")\n","else:\n","    chosen_param_grid = reduced_param_grid\n","    print(\"Using recommended reduced parameter grid\")\n","\n","# Print memory info to help with troubleshooting\n","print(f\"\\nAvailable memory before grid search: {psutil.virtual_memory().available / (1024 ** 3):.2f} GB\")\n","\n","# 9. Create and configure Random Forest model\n","use_class_weights = True  # Set to False if you don't want to use class weights\n","\n","if use_class_weights:\n","    print(\"Using class weights in the model\")\n","    base_model = RandomForestClassifier(\n","        class_weight=class_weight_dict,\n","        random_state=42,\n","        n_jobs=-1\n","    )\n","else:\n","    print(\"Not using class weights in the model\")\n","    base_model = RandomForestClassifier(\n","        random_state=42,\n","        n_jobs=-1\n","    )\n","\n","# Add parameters known to help with imbalanced datasets\n","# You can add these to any grid regardless of size\n","if grid_choice != \"3\":  # Only add if not using full grid\n","    chosen_param_grid['class_weight'] = ['balanced', 'balanced_subsample', class_weight_dict]\n","\n","print(\"Starting grid search with the following parameters:\")\n","for param, values in chosen_param_grid.items():\n","    print(f\"{param}: {values}\")\n","\n","# 10. Set up GridSearchCV with F2 scoring\n","grid_search = GridSearchCV(\n","    estimator=base_model,\n","    param_grid=chosen_param_grid,\n","    scoring=f2_scorer,  # Custom F2 scorer\n","    cv=5,               # 5-fold cross-validation\n","    n_jobs=2,           # Use limited number of cores to prevent memory issues\n","    verbose=2,\n","    pre_dispatch='2*n_jobs',  # Limit the number of jobs dispatched in parallel\n","    error_score=0.0    # Return this score instead of raising an error\n",")\n","\n","# 11. Run grid search\n","print(\"Running grid search (this may take some time)...\")\n","start_time = time.time()\n","\n","# Free up memory before starting\n","gc.collect()\n","\n","try:\n","    grid_search.fit(X_train_balanced_encoded, y_train_balanced)\n","except Exception as e:\n","    print(f\"\\nGrid search encountered an error: {e}\")\n","    print(\"\\nTrying with a smaller parameter grid...\")\n","\n","    # Define a smaller emergency parameter grid\n","    emergency_param_grid = {\n","        'n_estimators': [100],\n","        'max_depth': [10],\n","        'min_samples_split': [10],\n","        'min_samples_leaf': [4]\n","    }\n","\n","    # Create a new grid search with minimal parameters\n","    emergency_grid = GridSearchCV(\n","        estimator=base_model,\n","        param_grid=emergency_param_grid,\n","        scoring=f2_scorer,\n","        cv=3,  # Reduced cross-validation\n","        n_jobs=1,  # Single job to minimize memory usage\n","        verbose=2,\n","        error_score=0.0  # Return this score if error instead of raising\n","    )\n","\n","    # Try again with simplified parameters\n","    emergency_grid.fit(X_train_balanced_encoded, y_train_balanced)\n","\n","    # Replace the original grid search\n","    grid_search = emergency_grid\n","\n","end_time = time.time()\n","print(f\"Grid search completed in {(end_time - start_time) / 60:.2f} minutes!\")\n","\n","# 12. Output results\n","print(\"\\nBest parameters:\", grid_search.best_params_)\n","print(\"Best F2 score:\", grid_search.best_score_)\n","\n","# 13. Get the best model and make predictions\n","best_model = grid_search.best_estimator_\n","\n","# Save the best model\n","dump(best_model, 'best_rf_model.joblib')\n","print(\"Best model saved to 'best_rf_model.joblib'\")\n","\n","# Print training performance metrics\n","print(\"\\nTraining Performance Metrics:\")\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","print(f\"Best cross-validation F2 score: {grid_search.best_score_:.4f}\")\n","\n"]},{"cell_type":"code","source":["\n","# Make predictions - get probability for positive class\n","y_pred_proba = best_model.predict_proba(X_test_encoded)[:, 1]\n","\n","# Try different threshold values to optimize F2 score\n","print(\"\\nFinding optimal prediction threshold for F2 score...\")\n","thresholds = np.arange(0.1, 0.7, 0.05)\n","best_f2 = 0\n","best_threshold = 0.5  # Default\n","\n","for threshold in thresholds:\n","    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n","    f2 = fbeta_score(y_test, y_pred_threshold, beta=2)\n","    print(f\"Threshold {threshold:.2f}: F2 = {f2:.4f}\")\n","\n","    if f2 > best_f2:\n","        best_f2 = f2\n","        best_threshold = threshold\n","\n","print(f\"\\nOptimal threshold: {best_threshold:.2f} with F2 score: {best_f2:.4f}\")\n","\n","# Use the optimal threshold for final predictions\n","y_pred = (y_pred_proba >= best_threshold).astype(int)\n","\n","# 14. Evaluate the final model\n","# Calculate and print F2 score\n","f2 = fbeta_score(y_test, y_pred, beta=2)\n","print(f\"\\nF2 score on test set: {f2:.4f}\")\n","\n","# Print detailed classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Print confusion matrix\n","print(\"\\nConfusion Matrix:\")\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(conf_matrix)\n","\n","# Calculate additional metrics specifically for imbalanced data\n","tn, fp, fn, tp = conf_matrix.ravel()\n","sensitivity = tp / (tp + fn)  # same as recall\n","specificity = tn / (tn + fp)\n","precision = tp / (tp + fp)\n","npv = tn / (tn + fn)  # negative predictive value\n","\n","print(\"\\nAdditional Metrics for Imbalanced Data:\")\n","print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Negative Predictive Value: {npv:.4f}\")\n","print(f\"F1 Score: {2 * (precision * sensitivity) / (precision + sensitivity):.4f}\")\n","print(f\"F2 Score (emphasizes recall): {f2:.4f}\")\n","print(f\"Balanced Accuracy: {(sensitivity + specificity) / 2:.4f}\")\n","\n","# Feature importance analysis\n","print(\"\\nFeature Importance:\")\n","feature_names = X_train_balanced_encoded.columns\n","importance_df = pd.DataFrame({\n","    'Feature': feature_names,\n","    'Importance': best_model.feature_importances_\n","})\n","importance_df = importance_df.sort_values('Importance', ascending=False)\n","print(importance_df.head(20).to_string())  # Show top 20 features\n","\n","# Compare to CatBoost model if available\n","print(\"\\nIf you've already run the CatBoost model, compare the results to select the best approach.\")"],"metadata":{"id":"RE1mGum1dhtU","executionInfo":{"status":"ok","timestamp":1741466027931,"user_tz":360,"elapsed":9,"user":{"displayName":"Andrew Castillo","userId":"02822267340440655112"}}},"execution_count":null,"outputs":[]}]}